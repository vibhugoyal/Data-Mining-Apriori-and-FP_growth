{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apriori Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing our file\n",
    "\n",
    "we first preprocess our retail.txt file to include commas between it using:\n",
    "\n",
    "1. The function in notepad to replace the space with commas\n",
    "\n",
    "2. with open(r'C:\\Users\\Vijay Maruthi\\Downloads\\retail.txt','r') as file,open(r'C:\\Users\\Vijay           Maruthi\\Downloads\\_no_commas.txt','w') as target:\n",
    "    target.write(file.read().replace(',\\n','\\n'))\n",
    "    \n",
    "The second step is used to remove trailing commas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The code below is quite slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations, chain\n",
    "import time\n",
    "\n",
    "def load_transactions (path_to_data, order):\n",
    "    Transactions = []\n",
    "    with open (path_to_data, 'r') as fid:\n",
    "        for lines in fid:\n",
    "            str_line = list (lines.strip().split(','))\n",
    "            _t = list(np.unique(str_line))\n",
    "            _t.sort(key=lambda x: order.index(x))\n",
    "            Transactions.append(_t)\n",
    "    return Transactions\n",
    "\n",
    "def count_occurences(itemset, Transactions):\n",
    "    count=0\n",
    "    for i in range(len(Transactions)):\n",
    "        if set(itemset).issubset(set(Transactions[i])):\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "\n",
    "def join_two_itemsets (it1, it2, order):\n",
    "    it1.sort(key=lambda x: order.index(x))\n",
    "    it2.sort(key=lambda x: order.index(x))\n",
    "\n",
    "\n",
    "\n",
    "    for i in range (len (it1)-1):\n",
    "        if it1[i] != it2 [i]:\n",
    "            return []\n",
    "    \n",
    "    if order.index(it1[-1]) < order.index(it2[-1]):\n",
    "        return it1 + [it2[-1]]\n",
    "    return []\n",
    "\n",
    "def join_set_itemsets(set_of_its, order):\n",
    "    C = []\n",
    "    for i in range (len (set_of_its)):\n",
    "        for j in range (i+1, len(set_of_its)):\n",
    "            it_out = join_two_itemsets (set_of_its[i], set_of_its[j], order)\n",
    "            if len(it_out) > 0:\n",
    "                C.append(it_out)\n",
    "\n",
    "    return C\n",
    "\n",
    "def get_frequent(itemsets, Transactions, min_support, prev_discarded):\n",
    "    L = []\n",
    "    supp_count = []\n",
    "    new_discarded = []\n",
    "    k = len(prev_discarded.keys())\n",
    "    \n",
    "    for s in range (len (itemsets)):\n",
    "        discarded_before = False\n",
    "        if k > 0:\n",
    "            for it in prev_discarded[k]:\n",
    "                if set(it).issubset (set(itemsets[s])):\n",
    "                    discarded_before = True\n",
    "                    break\n",
    "                    \n",
    "        if not discarded_before:\n",
    "            count= count_occurences (itemsets[s], Transactions)\n",
    "            if count/len(Transactions) >= min_support:\n",
    "                L.append(itemsets[s])\n",
    "                supp_count.append(count)\n",
    "\n",
    "            else:\n",
    "                new_discarded.append(itemsets[s])\n",
    "    return L, supp_count, new_discarded\n",
    "\n",
    "def print_table(T,supp_count):\n",
    "    print(\"Itemset | Frequency\")\n",
    "    for k in range(len(T)):\n",
    "        print(\"{} | {} \".format(T[k],supp_count[k]))\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "def powerset(s):\n",
    "    return list(chain.from_iterable (combinations(s, r) for r in range(1, len(s)+ 1)))\n",
    "\n",
    "def write_rules(X, X_S, S, conf, supp, lift, num_trans):\n",
    "    out_rules=\"\"\n",
    "    out_rules += \"Freq. Itemset: \\n\".format(X)\n",
    "    out_rules += \" Rule: {} -> {} \\n\".format(list(S), list (X_S))\n",
    "    out_rules += \" Confidence: {0:2.3f} \".format(conf)\n",
    "    out_rules += \",Support: {0:2.3f} \".format(supp/num_trans)\n",
    "    out_rules +=\" ,Lift: {0:2.3f} \\n\".format(lift)\n",
    "    return out_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter minimum support value: 0.05\n",
      "Enter Minimum confidence value :0.2\n"
     ]
    }
   ],
   "source": [
    "# Loading the data\n",
    "\n",
    "path_to_data=\"retail_short.txt\" \n",
    "\n",
    "min_support=float(input(\"Enter minimum support value: \"))\n",
    "min_confidence=float(input(\"Enter Minimum confidence value :\"))\n",
    "\n",
    "order = [str(i) for i in range(20000)]\n",
    "\n",
    "Transactions=load_transactions(path_to_data, order)\n",
    "num_trans=len(Transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin = time.time()\n",
    "\n",
    "C = {}\n",
    "L = {}\n",
    "\n",
    "itemset_size = 1\n",
    "discarded={itemset_size : []}\n",
    "C.update({itemset_size: [[f] for f in order]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_count_L={}\n",
    "f, sup, new_discarded = get_frequent(C[itemset_size],Transactions,min_support,discarded)\n",
    "discarded.update({itemset_size : new_discarded})\n",
    "L.update({itemset_size : f})\n",
    "supp_count_L.update({itemset_size : sup})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1:\n",
      "\n",
      "Itemset | Frequency\n",
      "['32'] | 204 \n",
      "['38'] | 362 \n",
      "['39'] | 882 \n",
      "['41'] | 375 \n",
      "['48'] | 648 \n",
      "['1327'] | 76 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"L1:\\n\")\n",
    "print_table(L[1], supp_count_L[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table C2 : \n",
      "\n",
      "Itemset | Frequency\n",
      "['32', '38'] | 59 \n",
      "['32', '39'] | 116 \n",
      "['32', '41'] | 59 \n",
      "['32', '48'] | 100 \n",
      "['32', '1327'] | 10 \n",
      "['38', '39'] | 234 \n",
      "['38', '41'] | 133 \n",
      "['38', '48'] | 162 \n",
      "['38', '1327'] | 17 \n",
      "['39', '41'] | 292 \n",
      "['39', '48'] | 468 \n",
      "['39', '1327'] | 51 \n",
      "['41', '48'] | 196 \n",
      "['41', '1327'] | 22 \n",
      "['48', '1327'] | 38 \n",
      "\n",
      "\n",
      "\n",
      "Table L2 \n",
      "\n",
      "Itemset | Frequency\n",
      "['32', '39'] | 116 \n",
      "['32', '48'] | 100 \n",
      "['38', '39'] | 234 \n",
      "['38', '41'] | 133 \n",
      "['38', '48'] | 162 \n",
      "['39', '41'] | 292 \n",
      "['39', '48'] | 468 \n",
      "['41', '48'] | 196 \n",
      "\n",
      "\n",
      "\n",
      "Table C3 : \n",
      "\n",
      "Itemset | Frequency\n",
      "['32', '39', '48'] | 67 \n",
      "['38', '39', '41'] | 105 \n",
      "['38', '39', '48'] | 125 \n",
      "['38', '41', '48'] | 70 \n",
      "['39', '41', '48'] | 161 \n",
      "\n",
      "\n",
      "\n",
      "Table L3 \n",
      "\n",
      "Itemset | Frequency\n",
      "['38', '39', '41'] | 105 \n",
      "['38', '39', '48'] | 125 \n",
      "['39', '41', '48'] | 161 \n",
      "\n",
      "\n",
      "\n",
      "Table C4 : \n",
      "\n",
      "Itemset | Frequency\n",
      "['38', '39', '41', '48'] | 59 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CIK (we are going to need the join step from L[k-1])\n",
    "\n",
    "k=itemset_size+1\n",
    "convergence=False\n",
    "while not convergence:\n",
    "    C.update({ k: join_set_itemsets (L[k-1], order)})\n",
    "    print(\"Table C{} : \\n\".format(k))\n",
    "    print_table(C[k],[count_occurences(it, Transactions) for it in C[k]])\n",
    "    f, sup, new_discarded =get_frequent(C[k], Transactions, min_support, discarded)\n",
    "    discarded.update({k: new_discarded})\n",
    "    L.update({k: f})\n",
    "    supp_count_L.update({k: sup}) \n",
    "    if len(L[k]) == 0:\n",
    "        convergence =True\n",
    "    else:\n",
    "        print(\"Table L{} \\n\".format(k))\n",
    "        print_table(L[k],supp_count_L[k])\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the association rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to generate association rules is : 25.64456272125244\n",
      "\n",
      "Freq. Itemset: \n",
      " Rule: ['32'] -> ['39'] \n",
      " Confidence: 0.569 ,Support: 0.077  ,Lift: 0.969 \n",
      "Freq. Itemset: \n",
      " Rule: ['32'] -> ['48'] \n",
      " Confidence: 0.490 ,Support: 0.067  ,Lift: 1.137 \n",
      "Freq. Itemset: \n",
      " Rule: ['38'] -> ['39'] \n",
      " Confidence: 0.646 ,Support: 0.156  ,Lift: 1.102 \n",
      "Freq. Itemset: \n",
      " Rule: ['39'] -> ['38'] \n",
      " Confidence: 0.265 ,Support: 0.156  ,Lift: 1.102 \n",
      "Freq. Itemset: \n",
      " Rule: ['38'] -> ['41'] \n",
      " Confidence: 0.367 ,Support: 0.088  ,Lift: 1.473 \n",
      "Freq. Itemset: \n",
      " Rule: ['41'] -> ['38'] \n",
      " Confidence: 0.355 ,Support: 0.088  ,Lift: 1.473 \n",
      "Freq. Itemset: \n",
      " Rule: ['38'] -> ['48'] \n",
      " Confidence: 0.448 ,Support: 0.108  ,Lift: 1.038 \n",
      "Freq. Itemset: \n",
      " Rule: ['48'] -> ['38'] \n",
      " Confidence: 0.250 ,Support: 0.108  ,Lift: 1.038 \n",
      "Freq. Itemset: \n",
      " Rule: ['39'] -> ['41'] \n",
      " Confidence: 0.331 ,Support: 0.194  ,Lift: 1.327 \n",
      "Freq. Itemset: \n",
      " Rule: ['41'] -> ['39'] \n",
      " Confidence: 0.779 ,Support: 0.194  ,Lift: 1.327 \n",
      "Freq. Itemset: \n",
      " Rule: ['39'] -> ['48'] \n",
      " Confidence: 0.531 ,Support: 0.311  ,Lift: 1.231 \n",
      "Freq. Itemset: \n",
      " Rule: ['48'] -> ['39'] \n",
      " Confidence: 0.722 ,Support: 0.311  ,Lift: 1.231 \n",
      "Freq. Itemset: \n",
      " Rule: ['41'] -> ['48'] \n",
      " Confidence: 0.523 ,Support: 0.130  ,Lift: 1.212 \n",
      "Freq. Itemset: \n",
      " Rule: ['48'] -> ['41'] \n",
      " Confidence: 0.302 ,Support: 0.130  ,Lift: 1.212 \n",
      "Freq. Itemset: \n",
      " Rule: ['38'] -> ['39', '41'] \n",
      " Confidence: 0.290 ,Support: 0.070  ,Lift: 1.493 \n",
      "Freq. Itemset: \n",
      " Rule: ['41'] -> ['39', '38'] \n",
      " Confidence: 0.280 ,Support: 0.070  ,Lift: 1.798 \n",
      "Freq. Itemset: \n",
      " Rule: ['39', '38'] -> ['41'] \n",
      " Confidence: 0.449 ,Support: 0.070  ,Lift: 1.798 \n",
      "Freq. Itemset: \n",
      " Rule: ['41', '38'] -> ['39'] \n",
      " Confidence: 0.789 ,Support: 0.070  ,Lift: 1.345 \n",
      "Freq. Itemset: \n",
      " Rule: ['39', '41'] -> ['38'] \n",
      " Confidence: 0.360 ,Support: 0.070  ,Lift: 1.493 \n",
      "Freq. Itemset: \n",
      " Rule: ['38'] -> ['48', '39'] \n",
      " Confidence: 0.345 ,Support: 0.083  ,Lift: 1.109 \n",
      "Freq. Itemset: \n",
      " Rule: ['39', '38'] -> ['48'] \n",
      " Confidence: 0.534 ,Support: 0.083  ,Lift: 1.239 \n",
      "Freq. Itemset: \n",
      " Rule: ['48', '38'] -> ['39'] \n",
      " Confidence: 0.772 ,Support: 0.083  ,Lift: 1.315 \n",
      "Freq. Itemset: \n",
      " Rule: ['48', '39'] -> ['38'] \n",
      " Confidence: 0.267 ,Support: 0.083  ,Lift: 1.109 \n",
      "Freq. Itemset: \n",
      " Rule: ['41'] -> ['48', '39'] \n",
      " Confidence: 0.429 ,Support: 0.107  ,Lift: 1.379 \n",
      "Freq. Itemset: \n",
      " Rule: ['48'] -> ['39', '41'] \n",
      " Confidence: 0.248 ,Support: 0.107  ,Lift: 1.279 \n",
      "Freq. Itemset: \n",
      " Rule: ['39', '41'] -> ['48'] \n",
      " Confidence: 0.551 ,Support: 0.107  ,Lift: 1.279 \n",
      "Freq. Itemset: \n",
      " Rule: ['48', '39'] -> ['41'] \n",
      " Confidence: 0.344 ,Support: 0.107  ,Lift: 1.379 \n",
      "Freq. Itemset: \n",
      " Rule: ['48', '41'] -> ['39'] \n",
      " Confidence: 0.821 ,Support: 0.107  ,Lift: 1.400 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "assoc_rules_str =\"\"\n",
    "\n",
    "for i in range(1, len(L)): \n",
    "    for j in range(len (L[i])):\n",
    "        s = powerset(L[i][j])\n",
    "        s.pop()\n",
    "        for z in s:\n",
    "            S = set(z)\n",
    "            X= set (L[i] [j])\n",
    "            X_S = set(X-S)\n",
    "            sup_x= count_occurences (X, Transactions)\n",
    "            sup_x_s= count_occurences (X_S, Transactions)\n",
    "            conf = sup_x / count_occurences (S, Transactions)\n",
    "            lift = conf/ (sup_x_s/ num_trans)\n",
    "            if conf >= min_confidence and sup_x >= min_support:\n",
    "                assoc_rules_str+=write_rules (X, X_S, S, conf, sup_x, lift, num_trans)\n",
    "                \n",
    "# printing association rules\n",
    "                \n",
    "end=time.time()\n",
    "\n",
    "print(\"Time taken to generate association rules is :\",end-begin)\n",
    "print()\n",
    "print(assoc_rules_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
